Vision Transformer (ViT)
・画像をパッチ列に変換して NLP 型 Transformer で処理するという発想で、CNN の畳み込みを自己注意機構に置き換えたモデル
・エンコーダのみで構成　RにN+1, E_posが外に出る


・MLP層を初期化（新しいタスクに適用しやすくする）
・事前学習時とパッチサイズを揃える（事前学習したパラメータで効果的に推論）
・位置エンコーディングを2次元補間する（異なる解像度やパッチ構成に対応）
・Transformerへ入力する際に空間情報が失われるので、入力自体に位置情報の埋め込み（Position Embedding）を行う
・離れている画像パッチどうしのPosition Embeddingは似ておらず、近い画像パッチどうしは似る
・Position Embeddingはパッチ間の相対的な位置関係を表すため、距離が近いほどEmbeddingの類似度は大きくなります。

