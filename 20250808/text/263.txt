SHAP
・モデル予測を「ベースライン（特徴値未知時の期待出力；何もしないとこの値）」から「各特徴がどれだけ予測を押し上げ／押し下げたか」に分解
・「ベースライン→実際の入力」によって予測をどれだけ変化させたか（寄与度）を定量化
・各特徴が予測にどれだけ寄与したか→Shapley値
・Shapley値はゲーム理論にもとづく
・各特徴量の組み合わせは特徴量の階乗個になり計算量が莫大となるが、SHAPはそこを近似的に少ない計算で行えるようにした
